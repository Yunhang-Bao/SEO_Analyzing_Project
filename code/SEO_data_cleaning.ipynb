{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Set root directory paths for AWS\n",
        "root_dir = \"/var/www/html/separation_t4_t10/top3_and_top10_data\"\n",
        "output_dir = \"/var/www/html/separation_t4_t10/Part 1 - Exclusive\"\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Function to process a city\n",
        "def process_city(city_path, city_name):\n",
        "    \"\"\"\n",
        "    Process a single city to extract rank 4-10 results by removing top 3 results from top 10 data.\n",
        "    \n",
        "    Args:\n",
        "        city_path (str): Path to the city directory\n",
        "        city_name (str): Name of the city\n",
        "    \n",
        "    Returns:\n",
        "        int: Number of exclusive rank 4-10 results found\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Build file paths\n",
        "        top3_path = os.path.join(city_path, \"top_3_results_filtered.csv\")\n",
        "        top10_path = os.path.join(city_path, \"top_10_results_filtered.csv\")\n",
        "\n",
        "        # Check if both files exist\n",
        "        if not (os.path.exists(top3_path) and os.path.exists(top10_path)):\n",
        "            print(f\"Skipping {city_name}: Missing required files\")\n",
        "            return 0\n",
        "\n",
        "        # Read CSV files\n",
        "        try:\n",
        "            df_top3 = pd.read_csv(top3_path)\n",
        "            df_top10 = pd.read_csv(top10_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {city_name}: Error reading files - {e}\")\n",
        "            return 0\n",
        "\n",
        "        # Check for required columns\n",
        "        required_columns = ['link', 'keyword']\n",
        "        if not all(col in df_top3.columns for col in required_columns) or not all(col in df_top10.columns for col in required_columns):\n",
        "            print(f\"Skipping {city_name}: Missing required columns\")\n",
        "            return 0\n",
        "\n",
        "        # Create city output directory\n",
        "        city_output_dir = os.path.join(output_dir, city_name)\n",
        "        os.makedirs(city_output_dir, exist_ok=True)\n",
        "\n",
        "        # Get all unique keywords for this city\n",
        "        keywords = set(df_top3['keyword'].unique()) | set(df_top10['keyword'].unique())\n",
        "\n",
        "        # Store all 4-10 results from all keywords\n",
        "        all_exclusive_rows = []\n",
        "        keyword_stats = {}\n",
        "\n",
        "        # Process each keyword\n",
        "        for keyword in keywords:\n",
        "            # Filter data for this keyword\n",
        "            top3_keyword = df_top3[df_top3['keyword'] == keyword]\n",
        "            top10_keyword = df_top10[df_top10['keyword'] == keyword]\n",
        "\n",
        "            # Get unique links from top3\n",
        "            top3_links = set(top3_keyword['link'].dropna())\n",
        "\n",
        "            # Remove top3 links from top10 to get rank 4-10 results\n",
        "            mask = ~top10_keyword['link'].isin(top3_links)\n",
        "            df_exclusive = top10_keyword[mask].copy()\n",
        "\n",
        "            # If there are remaining results, collect them\n",
        "            if not df_exclusive.empty:\n",
        "                # Add a new column to identify these as 4-10 rank results\n",
        "                df_exclusive['rank_range'] = '4-10'\n",
        "\n",
        "                # Collect results\n",
        "                all_exclusive_rows.append(df_exclusive)\n",
        "\n",
        "                # Record statistics for this keyword\n",
        "                keyword_stats[keyword] = {\n",
        "                    'top3_count': len(top3_keyword),\n",
        "                    'top10_count': len(top10_keyword),\n",
        "                    'exclusive_count': len(df_exclusive)\n",
        "                }\n",
        "\n",
        "        # Combine and save results\n",
        "        if all_exclusive_rows:\n",
        "            # Combine all keyword results into one dataframe\n",
        "            combined_df = pd.concat(all_exclusive_rows, ignore_index=True)\n",
        "            combined_path = os.path.join(city_output_dir, f\"{city_name}_top_4_to_10_results.csv\")\n",
        "            combined_df.to_csv(combined_path, index=False)\n",
        "\n",
        "            # Create statistics file\n",
        "            stats_df = pd.DataFrame.from_dict(keyword_stats, orient='index')\n",
        "            stats_df.reset_index(inplace=True)\n",
        "            stats_df.rename(columns={'index': 'keyword'}, inplace=True)\n",
        "            stats_path = os.path.join(city_output_dir, f\"{city_name}_stats.csv\")\n",
        "            stats_df.to_csv(stats_path, index=False)\n",
        "\n",
        "            print(f\"Processed {city_name}: Aggregated {len(combined_df)} rank 4-10 results from {len(keyword_stats)} keywords\")\n",
        "            return len(combined_df)\n",
        "        else:\n",
        "            print(f\"Skipping {city_name}: No rank 4-10 results found\")\n",
        "            return 0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {city_name}: Processing error - {e}\")\n",
        "        return 0\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to process all cities and extract rank 4-10 results.\n",
        "    \"\"\"\n",
        "    # Check if root directory exists\n",
        "    if not os.path.exists(root_dir):\n",
        "        print(f\"Error: Root directory {root_dir} does not exist\")\n",
        "        return\n",
        "\n",
        "    # Statistics variables\n",
        "    total_exclusive_links = 0\n",
        "    processed_cities = 0\n",
        "    skipped_cities = []\n",
        "\n",
        "    # Get all city directories\n",
        "    all_cities = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
        "    print(f\"Starting to process {len(all_cities)} cities...\")\n",
        "\n",
        "    # Process each city\n",
        "    for dir_name in all_cities:\n",
        "        city_path = os.path.join(root_dir, dir_name)\n",
        "\n",
        "        # Process the city\n",
        "        exclusive_count = process_city(city_path, dir_name)\n",
        "\n",
        "        if exclusive_count > 0:\n",
        "            total_exclusive_links += exclusive_count\n",
        "            processed_cities += 1\n",
        "        else:\n",
        "            skipped_cities.append(dir_name)\n",
        "\n",
        "    # Print summary results\n",
        "    print(\"\\n----- Results Summary -----\")\n",
        "    print(f\"Successfully processed: {processed_cities}/{len(all_cities)} cities\")\n",
        "    print(f\"Skipped cities: {len(skipped_cities)}\")\n",
        "    if skipped_cities:\n",
        "        print(f\"Skipped city list: {', '.join(skipped_cities[:10])}{'...' if len(skipped_cities) > 10 else ''}\")\n",
        "    print(f\"Total rank 4-10 links: {total_exclusive_links}\")\n",
        "    print(f\"Average links per city: {total_exclusive_links / processed_cities if processed_cities > 0 else 0:.2f}\")\n",
        "\n",
        "    # Save overall summary to file\n",
        "    summary_data = {\n",
        "        'total_cities': len(all_cities),\n",
        "        'processed_cities': processed_cities,\n",
        "        'skipped_cities': len(skipped_cities),\n",
        "        'total_exclusive_links': total_exclusive_links,\n",
        "        'average_links_per_city': total_exclusive_links / processed_cities if processed_cities > 0 else 0\n",
        "    }\n",
        "    \n",
        "    summary_df = pd.DataFrame([summary_data])\n",
        "    summary_path = os.path.join(output_dir, \"processing_summary.csv\")\n",
        "    try:\n",
        "        summary_df.to_csv(summary_path, index=False)\n",
        "        print(f\"\\nProcessing summary saved to: {summary_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving summary: {e}\")\n",
        "\n",
        "# Execute main() when this script is run directly\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
